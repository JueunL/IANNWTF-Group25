{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW08_Jueun+cGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JueunL/IANNWTF-Group25/blob/Workflow/hw_02_group_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL0o3ZXsukmO"
      },
      "source": [
        "%load_ext tensorboard\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "import datetime\n",
        "%matplotlib notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnNIFBI3u4SA",
        "outputId": "6a173095-9bcc-4335-9799-eebf9cce1e0b"
      },
      "source": [
        "# Load the MNIST dataset.\n",
        "# Normalize to [-1,1]\n",
        "(train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "train_images = (train_images/255.0)*2 - 1\n",
        "train_images = np.reshape(train_images, newshape=[-1,28,28,1])\n",
        "train_images = train_images.astype(np.float32)\n",
        "\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tovRw1qFwTym"
      },
      "source": [
        "# Define the Generator.\n",
        "class Generator(tf.keras.layers.Layer):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        # In the Generator we take the Embedding and feed it into a dense layer\n",
        "        # This will get some more information out of the embedding since we \n",
        "        # increase the \"channel size\"\n",
        "        self.dense = tf.keras.layers.Dense(\n",
        "                            units=7*7*64,\n",
        "                            activation=None,\n",
        "                            use_bias=False\n",
        "            \n",
        "        )\n",
        "\n",
        "        # Now we perform BatchNorm (to prevent overfitting) and\n",
        "        # upsample the embedding to a proper image with a Convolutional Transpose Layer\n",
        "        # (after doing this three times we have the image)\n",
        "        self.batchnorm_1 = tf.keras.layers.BatchNormalization()\n",
        "        self.convT_1 = tf.keras.layers.Conv2DTranspose(\n",
        "                            filters=32,\n",
        "                            kernel_size=5,\n",
        "                            strides=1,\n",
        "                            padding='SAME',\n",
        "                            activation=None,\n",
        "                            use_bias=False\n",
        "        )\n",
        "        self.batchnorm_2 = tf.keras.layers.BatchNormalization()\n",
        "        self.convT_2 = tf.keras.layers.Conv2DTranspose(\n",
        "                            filters=16,\n",
        "                            kernel_size=5,\n",
        "                            strides=2,\n",
        "                            padding='SAME',\n",
        "                            activation=None,\n",
        "                            use_bias=False\n",
        "        )\n",
        "        self.batchnorm_3 = tf.keras.layers.BatchNormalization()\n",
        "        self.convT_3 = tf.keras.layers.Conv2DTranspose(\n",
        "                            filters=1,\n",
        "                            kernel_size=5,\n",
        "                            strides=2,\n",
        "                            padding='SAME',\n",
        "                            activation=tf.nn.tanh,\n",
        "                            use_bias=False\n",
        "        )\n",
        "        \n",
        "    def call(self,x,is_training):\n",
        "        # Here we pass the input thru all layers in the order they were specified\n",
        "        x = self.dense(x)\n",
        "\n",
        "        # In the BatchNorm layers we specify if we are currently training or testing\n",
        "        # the generator\n",
        "        x = self.batchnorm_1(x, training=is_training)\n",
        "        \n",
        "        # Like always we have to add the activation after the batchnorm\n",
        "        x = tf.nn.leaky_relu(x)\n",
        "        x = tf.reshape(x, shape=(-1, 7, 7, 64))\n",
        "        x = self.convT_1(x)\n",
        "        x = self.batchnorm_2(x, training=is_training)\n",
        "        x = tf.nn.leaky_relu(x)\n",
        "        x = self.convT_2(x)\n",
        "        x = self.batchnorm_3(x, training=is_training)\n",
        "        x = tf.nn.leaky_relu(x)\n",
        "        x = self.convT_3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n32s4YTwct7"
      },
      "source": [
        "# Define the Discriminator.\n",
        "class Discriminator(tf.keras.layers.Layer):\n",
        "     \n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        # Firstly we perform two convolution steps to downsample the image\n",
        "        self.conv_1 = tf.keras.layers.Conv2D(\n",
        "                            filters = 8,\n",
        "                            kernel_size =5, \n",
        "                            strides=2,\n",
        "                            padding=\"SAME\",\n",
        "                            activation=tf.nn.leaky_relu\n",
        "                            \n",
        "        )\n",
        "        self.conv_2 = tf.keras.layers.Conv2D(\n",
        "                            filters = 16,\n",
        "                            kernel_size =5, \n",
        "                            strides=2,\n",
        "                            padding=\"SAME\",\n",
        "                            activation=tf.nn.leaky_relu\n",
        "        )        \n",
        "        # Now we flatten the image and use a Dense layer to classify the image\n",
        "        # using a single unit and sigmoid for activation\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.output_layer = tf.keras.layers.Dense(\n",
        "                            units = 1,\n",
        "                            activation=tf.nn.sigmoid\n",
        "        )\n",
        "        \n",
        "    def call(self, x, is_training):\n",
        "        x = self.conv_1(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJoJIIzCwp2I"
      },
      "source": [
        "# Define the dataset.\n",
        "dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
        "dataset = dataset.shuffle(buffer_size=1000)\n",
        "dataset = dataset.batch(batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjqqJq33wtVF"
      },
      "source": [
        "# Define the loss for the generator.\n",
        "def generator_loss(probabilities):\n",
        "    # Get only the output probabilities for the fake images.\n",
        "    probabilities_fake = probabilities[:32]\n",
        "    # Create the label vector indicating that the images are correct (=1).\n",
        "    labels_one = tf.convert_to_tensor(np.ones(shape=(32,1)))\n",
        "    # Use binary cross entropy loss to compute the loss. tf.keras.losses.BinaryCrossentropy()\n",
        "    binary = tf.keras.losses.BinaryCrossentropy()\n",
        "    loss = binary(labels_one,probabilities_fake)\n",
        "    return loss\n",
        "\n",
        "# Define the loss for the discriminator.\n",
        "def discriminator_loss(probabilities):\n",
        "    # Create the label vector indicating which images are real and which are fake.\n",
        "    labels_one = tf.convert_to_tensor(np.ones(shape=(32,1)))\n",
        "    labels_zero = tf.convert_to_tensor(np.zeros(shape=(32,1)))\n",
        "    labels = tf.concat([labels_zero, labels_one], axis=0)\n",
        "    # Use binary cross entropy loss to compute the loss.\n",
        "    binary = tf.keras.losses.BinaryCrossentropy()\n",
        "    loss = binary(labels,probabilities)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "GEk-Yvt8w3U2",
        "outputId": "cb061e2d-2330-4792-9ddb-099f36ba3c90"
      },
      "source": [
        "!rm -rf ./logs/ \n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "\n",
        "# For me the in-notebook tensorboard sometimes doesn't work. In this case maybe just use your terminal\n",
        "# if you work on your own machine. (comment out the following line)\n",
        "%tensorboard --logdir logs/\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Initialzing generator and discriminator.\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "# Define size of latent variable vector.\n",
        "z_dim = 100\n",
        "# Define random noise to use for generating 8 images for supervision.\n",
        "seed = tf.random.normal(shape=[8,z_dim])\n",
        "\n",
        "# Initialize two optimizers (one for generator, one for discriminator).\n",
        "# During training you will have to do every step twice (computing loss, computing gradients,\n",
        "# applying gradients, storing loss in summary). Namely once for generator and once for discriminator.\n",
        "gen_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "dis_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "step=0\n",
        "\n",
        "for epochs in range(25):\n",
        "    for real in dataset:\n",
        "        \n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
        "            \n",
        "            # Generate random noise vector. tf.random.normal()\n",
        "            noise = tf.random.normal(shape=[32, z_dim])\n",
        "            # Generate fake images with generator.\n",
        "            fake = generator(noise, is_training=True)\n",
        "            # Merge fake and real images to a long vector. tf.concat()\n",
        "            images = tf.concat([fake, real], axis=0)\n",
        "            # Compute output from discriminator.\n",
        "            probs = discriminator(images, is_training=True)\n",
        "            \n",
        "            # Compute loss, compute gradients, apply gradients, store summaries.\n",
        "            gen_loss = generator_loss(probs)\n",
        "            dis_loss = discriminator_loss(probs)\n",
        "            gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "            dis_gradients = dis_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
        "\n",
        "            gen_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
        "            dis_optimizer.apply_gradients(zip(dis_gradients, discriminator.trainable_variables))\n",
        "\n",
        "            with train_summary_writer.as_default():\n",
        "                tf.summary.scalar('generator_loss', gen_loss, step=step)\n",
        "                tf.summary.scalar('discriminator_loss', dis_loss, step=step)\n",
        "            \n",
        "        # Every 100 steps generate images from the defined seed and \n",
        "        # store to supervise how well the generator works.\n",
        "        if step % 100 == 0:\n",
        "            fake = generator(seed, is_training=False)\n",
        "            with test_summary_writer.as_default():\n",
        "                # Before showing the fake images we also have to bring them back in \n",
        "                # range 0:1 (for training we used -1:1)\n",
        "                tf.summary.image('fake_images', (fake + 1) / 2, step=step, max_outputs=8)\n",
        "            \n",
        "        step += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTLij90TCKf-"
      },
      "source": [
        "### cGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5dX9NlDqv_N"
      },
      "source": [
        "(img, label), _ = tf.keras.datasets.fashion_mnist.load_data()\n",
        "img = (img / 255) * 2 - 1\n",
        "img = np.reshape(img, newshape=[-1,28,28,1])\n",
        "img = img.astype(np.float32)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "img = tf.data.Dataset.from_tensor_slices(img)\n",
        "label = tf.data.Dataset.from_tensor_slices(label)\n",
        "data = tf.data.Dataset.zip((img,label))\n",
        "data = data.shuffle(buffer_size=1000).batch(batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5RKqvpPCOwH"
      },
      "source": [
        "class cGAN_Discriminator(tf.keras.Model):\n",
        "  def __init__(self, input_shape=(28,28,1), n_classes=10):\n",
        "    super(cGAN_Discriminator, self).__init__()\n",
        "\n",
        "    self.label_layers = []\n",
        "    self.image_layers = []\n",
        "\n",
        "    # Turn the label into a embedding of size 50 \n",
        "    # (for each label the discriminator will learn a different embedding)\n",
        "    self.label_layers.append(layers.Embedding(n_classes, 50))\n",
        "    \n",
        "    # Now we scale up the embedding to the amount of pixels the images have\n",
        "    self.label_layers.append(layers.Dense(input_shape[0]*input_shape[1]))\n",
        "\n",
        "    # To get the correct dimensions and not a flat image we reshape the pixels\n",
        "    self.label_layers.append(layers.Reshape(input_shape))\n",
        "\n",
        "    # Merge image and label (the label becomes another channel)\n",
        "    self.merge = layers.Concatenate()\n",
        "\n",
        "    # Now we can define the classifier\n",
        "    # We start with two Convolutional layers\n",
        "    for _ in range(2):\n",
        "      self.image_layers.append(layers.Conv2D(128, (3,3), (2,2), \"same\"))\n",
        "      self.image_layers.append(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Now we flatten the images with GlobalAveragePooling\n",
        "    self.image_layers.append(layers.GlobalAveragePooling2D())\n",
        "\n",
        "    # To prevent overfitting we apply Dropout\n",
        "    self.image_layers.append(layers.Dropout(0.4))\n",
        "\n",
        "    # And get our prediction using a final Dense Layers\n",
        "    # (Due to GANs taking long to train we won't use more Dense Layers,\n",
        "    # but if you have the time to spend knock yourself out)\n",
        "    self.image_layers.append(layers.Dense(1, \"sigmoid\"))\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, x_img, x_lab):\n",
        "    for layer in self.label_layers:\n",
        "      x_lab = layer(x_lab)\n",
        "\n",
        "    x = self.merge([x_img, x_lab])\n",
        "\n",
        "    for layer in self.image_layers:\n",
        "      x = layer(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opyzppK6CRNs"
      },
      "source": [
        "class cGAN_Generator(tf.keras.Model):\n",
        "  def __init__(self, latent_dim, n_classes=10):\n",
        "    super(cGAN_Generator, self).__init__()\n",
        "\n",
        "    self.label_layers = []\n",
        "    self.embedding_layers = []\n",
        "    self.image_layers = []\n",
        "\n",
        "    # Here everything is like in the Generator, except we \n",
        "    # shape to a size of 7x7 matching the size of the embeddings\n",
        "    self.label_layers.append(layers.Embedding(n_classes, 50))\n",
        "    self.label_layers.append(layers.Dense(7*7))\n",
        "    self.label_layers.append(layers.Reshape((7,7,1)))\n",
        "\n",
        "    # Now we generate the Embeddings from the randomly generated\n",
        "    # latent values\n",
        "    self.embedding_layers.append(layers.Dense(128*7*7))\n",
        "    self.embedding_layers.append(layers.LeakyReLU(alpha=0.2))\n",
        "    self.embedding_layers.append(layers.Reshape((7,7,128)))\n",
        "\n",
        "    self.merge = layers.Concatenate()\n",
        "\n",
        "    for _ in range(2):\n",
        "      self.image_layers.append(layers.Conv2DTranspose(128, (4,4), (2,2), \"same\"))\n",
        "      self.image_layers.append(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    self.image_layers.append(layers.Conv2D(1, (7,7), padding=\"same\", activation=\"tanh\"))\n",
        "\n",
        "  #@tf.function\n",
        "  def __call__(self, x):\n",
        "    # Split image and label\n",
        "    x_img = x[0]\n",
        "    x_lab = x[1]\n",
        "\n",
        "    for layer in self.label_layers:\n",
        "      x_lab = layer(x_lab)\n",
        "    \n",
        "    for layer in self.embedding_layers:\n",
        "      x_img = layer(x_img)\n",
        "\n",
        "    x = self.merge([x_img, x_lab])\n",
        "\n",
        "    for layer in self.image_layers:\n",
        "      x = layer(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFr25GMu2HwP"
      },
      "source": [
        "# Define the loss for the generator.\n",
        "def generator_loss(probabilities):\n",
        "    # Get only the output probabilities for the fake images.\n",
        "    probabilities_fake = probabilities[:BATCH_SIZE]\n",
        "    # Create the label vector indicating that the images are correct (=1).\n",
        "    labels_one = tf.convert_to_tensor(np.ones(shape=(len(probabilities_fake),1)))\n",
        "    # Use binary cross entropy loss to compute the loss. tf.keras.losses.BinaryCrossentropy()\n",
        "    binary = tf.keras.losses.BinaryCrossentropy()\n",
        "    loss = binary(labels_one,probabilities_fake)\n",
        "    return loss\n",
        "\n",
        "# Define the loss for the discriminator.\n",
        "def discriminator_loss(probabilities):\n",
        "    # Create the label vector indicating which images are real and which are fake.\n",
        "    labels_one = tf.convert_to_tensor(np.ones(shape=(BATCH_SIZE,1)))\n",
        "    labels_zero = tf.convert_to_tensor(np.zeros(shape=(len(probabilities) - BATCH_SIZE,1)))\n",
        "    labels = tf.concat([labels_zero, labels_one], axis=0)\n",
        "    # Use binary cross entropy loss to compute the loss.\n",
        "    binary = tf.keras.losses.BinaryCrossentropy()\n",
        "    loss = binary(labels,probabilities)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBPcjutYCWeR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "outputId": "165fdd54-5476-4558-f06a-6a97fbe83505"
      },
      "source": [
        "!rm -rf ./logs/ \n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "\n",
        "# For me the in-notebook tensorboard sometimes doesn't work. In this case maybe just use your terminal\n",
        "# if you work on your own machine. (comment out the following line)\n",
        "%tensorboard --logdir logs/\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "# Define size of latent variable vector.\n",
        "z_dim = 100\n",
        "\n",
        "# Initialzing generator and discriminator.\n",
        "generator = cGAN_Generator(z_dim)\n",
        "discriminator = cGAN_Discriminator()\n",
        "\n",
        "# Define random noise to use for generating 10 images for supervision. (one for each class)\n",
        "seed = tf.random.normal(shape=[10,z_dim])\n",
        "sup_labels = tf.convert_to_tensor(list(range(0,10)))\n",
        "\n",
        "# Initialize two optimizers (one for generator, one for discriminator).\n",
        "# During training you will have to do every step twice (computing loss, computing gradients,\n",
        "# applying gradients, storing loss in summary). Namely once for generator and once for discriminator.\n",
        "gen_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "dis_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "step=0\n",
        "\n",
        "for epochs in range(25):\n",
        "    for real in data:\n",
        "        \n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
        "            \n",
        "            # Generate random noise vector. tf.random.normal()\n",
        "            noise = tf.random.normal(shape=[BATCH_SIZE, z_dim])\n",
        "            labels = tf.random.uniform([BATCH_SIZE], 0, 10, tf.int32)\n",
        "\n",
        "            # Generate fake images with generator.\n",
        "            fake = generator([noise, labels])\n",
        "            # Merge fake and real images to a long vector. tf.concat()\n",
        "            images = tf.concat([fake, real[0]], axis=0)\n",
        "            # Compute output from discriminator.\n",
        "            labels_real = tf.cast(real[1], tf.int32)\n",
        "\n",
        "            probs = discriminator(images, tf.concat([labels, labels_real],0))\n",
        "            \n",
        "            # Compute loss, compute gradients, apply gradients, store summaries.\n",
        "            gen_loss = generator_loss(probs)\n",
        "            dis_loss = discriminator_loss(probs)\n",
        "            gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "            dis_gradients = dis_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
        "\n",
        "            gen_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
        "            dis_optimizer.apply_gradients(zip(dis_gradients, discriminator.trainable_variables))\n",
        "\n",
        "            with train_summary_writer.as_default():\n",
        "                tf.summary.scalar('generator_loss', gen_loss, step=step)\n",
        "                tf.summary.scalar('discriminator_loss', dis_loss, step=step)\n",
        "            \n",
        "        # Every 500 steps generate images from the defined seed and \n",
        "        # store to supervise how well the generator works.\n",
        "        if step % 500 == 0:\n",
        "            # To get the best fakes possible each 500 steps we generate\n",
        "            # a variable number of fakes and only show the image that fooled the\n",
        "            # discriminator the most (one fake per class)\n",
        "            best_fakes = []\n",
        "            NUM_FAKES = 10\n",
        "            for i in range(10):\n",
        "                seed = tf.random.normal(shape=[NUM_FAKES,z_dim])\n",
        "                fake = generator([seed, np.asarray([i]*NUM_FAKES)])\n",
        "                prob = discriminator(fake, np.asarray([i]*NUM_FAKES))\n",
        "                best_fakes.append(fake[np.argmax(prob)])\n",
        "\n",
        "            with test_summary_writer.as_default():\n",
        "                # Before showing the fake images we also have to bring them back in \n",
        "                # range 0:1 (for training we used -1:1)\n",
        "                tf.summary.image(\"fake images\", (np.asarray(best_fakes) + 1) / 2, step=step, max_outputs=10)\n",
        "            \n",
        "        step += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKH0bKFXCdsK"
      },
      "source": [
        "# This makes sure that there is no colab timeout while training\n",
        "while True:pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YLqqJLT1n7N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}